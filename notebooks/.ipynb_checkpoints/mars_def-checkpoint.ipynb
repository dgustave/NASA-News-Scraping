{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver                    # Import module \n",
    "from selenium.webdriver.common.keys import Keys   # For keyboard keys \n",
    "from selenium.webdriver.chrome.service import Service # Start and stop browser service\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup as bs               # parse this html\n",
    "import time     # Waiting function for page to load\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I declared the dictionary outside the function to update the dictionary:\n",
    "mars_dict = {}\n",
    "\n",
    "# I want it to reinitialize the driver for every funtion. \n",
    "# It implicity waits 30 seconds to perform all task in the drivers session. \n",
    "def init_driver():\n",
    "    # Locate Driver in system\n",
    "    Path = \"C:\\SeleniumDrivers\\chromedriver.exe\"\n",
    "    service = Service(Path)\n",
    "    service.start()\n",
    "    driver = webdriver.Remote(service.service_url)\n",
    "    driver.implicitly_wait(30) \n",
    "    return driver\n",
    "\n",
    "\n",
    "def scrape_news(): \n",
    "    news = \"https://mars.nasa.gov/news/\"\n",
    "    driver = init_driver()\n",
    "    # Retrieve the latest news title\n",
    "    driver.get(news)\n",
    "    title_elements = driver.find_elements_by_class_name(\"content_title\")\n",
    "    title_htmls = [title_element.get_attribute(\"innerHTML\") for title_element in title_elements]\n",
    "    title_html = title_htmls[1]\n",
    "    news_soup = bs(title_html, 'lxml')\n",
    "    title = news_soup.get_text()\n",
    "\n",
    "    teaser_element = driver.find_element_by_class_name(\"article_teaser_body\")\n",
    "    teaser_html = teaser_element.get_attribute(\"innerHTML\")\n",
    "    mars_dict['title'] = title\n",
    "    mars_dict['summary'] = teaser_html \n",
    "    driver.quit()\n",
    "    return mars_dict\n",
    "\n",
    "def scrape_featured():\n",
    "    featured = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    driver = init_driver()\n",
    "    driver.get(featured);\n",
    "    featured_page_url_element = driver.find_element_by_xpath(\"//*[@id='full_image']\")\n",
    "    featured_page_url_element.click()\n",
    "    featured_link_element = driver.find_element_by_link_text('more info')\n",
    "    featured_link_element.click()\n",
    "    featured_image_elements = driver.find_elements_by_class_name('main_image')\n",
    "    featured_image_links = [featured_image_element.get_attribute(\"src\") for featured_image_element in featured_image_elements]\n",
    "    featured_image_link = featured_image_links[0]\n",
    "    mars_dict['featured_image'] = featured_image_link\n",
    "    driver.quit()\n",
    "    return mars_dict\n",
    "\n",
    "def scrape_table():\n",
    "    facts = \"https://space-facts.com/mars/\"\n",
    "    tables = pd.read_html(facts)\n",
    "    facts_df = tables[0]\n",
    "    facts_df.columns = [\"Mars Attributes\", \"Data\"]\n",
    "    fact_html = facts_df.to_html()\n",
    "    mars_dict['fact_table'] = str(fact_html)\n",
    "    return mars_dict\n",
    "\n",
    "def scrape_hemisphere():\n",
    "    hemisphere = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    hemi_dict = {} \n",
    "    driver = init_driver()\n",
    "    driver.get(hemisphere); # Add Urls Here!\n",
    "    hemisphere_elements = driver.find_elements_by_tag_name('h3')\n",
    "    hemisphere_elements[0].click()\n",
    "    hemi_links = driver.find_elements_by_class_name('wide-image')\n",
    "    cerb_links = [cerb_img.get_attribute(\"src\") for cerb_img in hemi_links]\n",
    "    cerb_link = cerb_links[0]\n",
    "    driver.back()\n",
    "    driver.refresh()\n",
    "\n",
    "    hemisphere_elements = driver.find_elements_by_tag_name('h3')\n",
    "    hemisphere_elements[1].click()\n",
    "    hemi2_links = driver.find_elements_by_class_name('wide-image')\n",
    "    schi_links = [schi_img.get_attribute(\"src\") for schi_img in hemi2_links]\n",
    "    schi_link = schi_links[0]\n",
    "    driver.back()\n",
    "    driver.refresh()\n",
    "\n",
    "    hemisphere_elements = driver.find_elements_by_tag_name('h3')\n",
    "    hemisphere_elements[2].click()\n",
    "    hemi3_links = driver.find_elements_by_class_name('wide-image')\n",
    "    syrt_links = [schi_img.get_attribute(\"src\") for schi_img in hemi3_links]\n",
    "    syrt_link = syrt_links[0]\n",
    "    driver.back()\n",
    "    driver.refresh()\n",
    "\n",
    "    hemisphere_elements = driver.find_elements_by_tag_name('h3')\n",
    "    hemisphere_elements[3].click()\n",
    "    hemi4_links = driver.find_elements_by_class_name('wide-image')\n",
    "    vall_links = [schi_img.get_attribute(\"src\") for schi_img in hemi4_links]\n",
    "    vall_link = vall_links[0]\n",
    "    driver.back()\n",
    "    driver.refresh() \n",
    "\n",
    "    hemisphere_elements = driver.find_elements_by_tag_name('h3')\n",
    "    hemisphere_element_htmls = [hemisphere_element.get_attribute(\"innerHTML\") for hemisphere_element in hemisphere_elements]\n",
    "    hemi_image = [cerb_link, schi_link, syrt_link,  vall_link]\n",
    "    hemi_dict['title'] = hemisphere_element_htmls\n",
    "    hemi_dict['img_url'] = hemi_image  \n",
    "    hemi_list = [hemi_dict]\n",
    "    mars_dict['hemisphere_images'] = hemi_list\n",
    "    driver.quit()\n",
    "    return mars_dict\n",
    "\n",
    "# Make all functions wait to see results for each function in this sequence: \n",
    "# This will give the dictionary time to update in mongo in py file even in bulk. \n",
    "def run():  \n",
    "    scrape_news()\n",
    "    time.sleep(5)\n",
    "    scrape_featured() \n",
    "    time.sleep(5)\n",
    "    scrape_table()\n",
    "    time.sleep(5)\n",
    "    scrape_hemisphere()\n",
    "    time.sleep(5)\n",
    "    return mars_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I plan to run all functions under the run definition:\n",
    "run = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
